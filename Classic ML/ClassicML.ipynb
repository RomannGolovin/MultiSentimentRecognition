{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "916fb769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4526ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d5f94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import nltk.tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import gensim.downloader\n",
    "import string\n",
    "import gensim\n",
    "from string import punctuation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dce7bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ab37b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaping(lst):\n",
    "    ans = []\n",
    "    for i in range(len(lst)):\n",
    "        ans.append([lst[i]])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aeab29",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fc48c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced 0.1\n",
      "acc 0.691 f1 0.696 time 3.729391098022461\n"
     ]
    }
   ],
   "source": [
    "count_iter = 0\n",
    "times = []\n",
    "times.append(time.time())\n",
    "penalty = ['l1', 'l2', 'elasticnet', None]\n",
    "class_weight = ['balanced',None]\n",
    "\n",
    "for weight in [None,'balanced']:   \n",
    "    for C in [0.1]:\n",
    "        if weight == 'balanced':\n",
    "            temp_weight = 'balanced'\n",
    "        else:\n",
    "            temp_weight = 'None'\n",
    "        print(temp_weight, C)\n",
    "        clf = LogisticRegression(class_weight=weight, C=C)\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        times.append(time.time())\n",
    "        test_acc = accuracy_score(y_test, pred)\n",
    "        test_f1 = f1_score(y_test, pred, average='weighted') \n",
    "        print('acc {} f1 {} time {}'.format(round(test_acc,3),round(test_f1,3), times[-1]-times[-2]))\n",
    "        temp_ans = [lemm_column_name, temp_weight, C, test_acc, test_f1,times[-1]-times[-2]]\n",
    "        df_result.loc[df_result.shape[0]-1] = temp_ans\n",
    "        count_iter += 1\n",
    "        clf = None\n",
    "        del clf\n",
    "        pred = None\n",
    "        del pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fed088",
   "metadata": {},
   "source": [
    "# NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7713f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.516 f1 0.409 time 4.924217700958252\n"
     ]
    }
   ],
   "source": [
    "df_result = pd.DataFrame([], columns=['lemm_column','test_acc','test_f1', 'time'])\n",
    "count_iter = 0\n",
    "times = []\n",
    "times.append(time.time())\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "times.append(time.time())\n",
    "test_acc = accuracy_score(y_test, pred)\n",
    "test_f1 = f1_score(y_test, pred, average='weighted') \n",
    "print('acc {} f1 {} time {}'.format(round(test_acc,3),round(test_f1,3), times[-1]-times[-2]))\n",
    "temp_ans = [lemm_column_name, test_acc, test_f1,times[-1]-times[-2]]\n",
    "df_result.loc[df_result.shape[0]-1] = temp_ans\n",
    "df_result.to_excel('./Результаты классический ml/df_nb_{}.xlsx'.format(count_iter),index=False)\n",
    "count_iter += 1\n",
    "clf = None\n",
    "del clf\n",
    "pred = None\n",
    "del pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92aa81",
   "metadata": {},
   "source": [
    "# dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c6bff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None gini 1\n",
      "acc 0.548 f1 0.548 time 144.21212124824524\n",
      "None entropy 1\n",
      "acc 0.551 f1 0.551 time 189.13862299919128\n",
      "None log_loss 1\n",
      "acc 0.55 f1 0.55 time 187.95779705047607\n",
      "balanced gini 1\n",
      "acc 0.548 f1 0.547 time 252.28252577781677\n",
      "balanced entropy 1\n",
      "acc 0.551 f1 0.55 time 270.14551854133606\n",
      "balanced log_loss 1\n",
      "acc 0.552 f1 0.552 time 268.8990321159363\n"
     ]
    }
   ],
   "source": [
    "for weight in [None,'balanced']:\n",
    "#     for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    for criterion in ['gini', 'entropy', 'log_loss']:\n",
    "        if weight == 'balanced':\n",
    "            temp_weight = 'balanced'\n",
    "        else:\n",
    "            temp_weight = 'None'\n",
    "        print(temp_weight, criterion)\n",
    "        clf = DecisionTreeClassifier(class_weight=weight, criterion=criterion)\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        times.append(time.time())\n",
    "        test_acc = accuracy_score(y_test, pred)\n",
    "        test_f1 = f1_score(y_test, pred, average='weighted') \n",
    "        print('acc {} f1 {} time {}'.format(round(test_acc,3),round(test_f1,3), times[-1]-times[-2]))\n",
    "        clf = None\n",
    "        del clf\n",
    "        pred = None\n",
    "        del pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35f7acc",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86277dc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced poly 0.1\n",
      "acc 0.564 f1 0.503 time 96.32277393341064\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m f1 \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m time \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mround\u001b[39m(test_acc,\u001b[38;5;241m3\u001b[39m),\u001b[38;5;28mround\u001b[39m(test_f1,\u001b[38;5;241m3\u001b[39m), times[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mtimes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m     24\u001b[0m             temp_ans \u001b[38;5;241m=\u001b[39m [lemm_column_name, temp_weight, kernel, C, test_acc, test_f1,times[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mtimes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]]\n\u001b[1;32m---> 25\u001b[0m             df_result\u001b[38;5;241m.\u001b[39mloc[df_result\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m temp_ans\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#             df_result.to_excel('./Результаты классический ml/df_svm_{}.xlsx'.format(count_iter),index=False)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m             count_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    848\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 849\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1825\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1822\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 1825\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_missing(indexer, value)\n\u001b[0;32m   1826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1829\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:2158\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   2155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value):\n\u001b[0;32m   2156\u001b[0m         \u001b[38;5;66;03m# must have conforming columns\u001b[39;00m\n\u001b[0;32m   2157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m-> 2158\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot set a row with mismatched columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2160\u001b[0m     value \u001b[38;5;241m=\u001b[39m Series(value, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns, name\u001b[38;5;241m=\u001b[39mindexer)\n\u001b[0;32m   2162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj):\n\u001b[0;32m   2163\u001b[0m     \u001b[38;5;66;03m# We will ignore the existing dtypes instead of using\u001b[39;00m\n\u001b[0;32m   2164\u001b[0m     \u001b[38;5;66;03m#  internals.concat logic\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "for weight in [None,'balanced']:\n",
    "#     for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    for kernel in ['poly']:\n",
    "#         for C in [0.01, 0.1, 1]:\n",
    "        for C in [0.1]:\n",
    "            if weight == 'balanced':\n",
    "                temp_weight = 'balanced'\n",
    "            else:\n",
    "                temp_weight = 'None'\n",
    "            print(temp_weight, kernel, C)\n",
    "            clf = SVC(class_weight=weight, C=C, kernel=kernel)\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred = clf.predict(X_test)\n",
    "            times.append(time.time())\n",
    "            test_acc = accuracy_score(y_test, pred)\n",
    "            test_f1 = f1_score(y_test, pred, average='weighted') \n",
    "            print('acc {} f1 {} time {}'.format(round(test_acc,3),round(test_f1,3), times[-1]-times[-2]))\n",
    "            clf = None\n",
    "            del clf\n",
    "            pred = None\n",
    "            del pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fa39fc",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff773ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform 9\n",
      "acc 0.713 f1 0.696 time 14.179454803466797\n"
     ]
    }
   ],
   "source": [
    "for weight in ['uniform']:    \n",
    "    for neigh in [9]:\n",
    "        print(weight, neigh)\n",
    "        clf = KNeighborsClassifier(n_neighbors=neigh)\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        times.append(time.time())\n",
    "        test_acc = accuracy_score(y_test, pred)\n",
    "        test_f1 = f1_score(y_test, pred, average='weighted') \n",
    "        print('acc {} f1 {} time {}'.format(round(test_acc,3),round(test_f1,3), times[-1]-times[-2]))\n",
    "        clf = None\n",
    "        del clf\n",
    "        pred = None\n",
    "        del pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544a095",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f09e6eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto svd\n",
      "error\n",
      "auto lsqr\n",
      "acc 0.629 f1 0.622 time 9.36988377571106\n",
      "auto eigen\n",
      "acc 0.629 f1 0.622 time 9.002815008163452\n",
      "None svd\n",
      "acc 0.629 f1 0.622 time 10.618637323379517\n",
      "None lsqr\n",
      "acc 0.629 f1 0.622 time 6.040789604187012\n",
      "None eigen\n",
      "acc 0.629 f1 0.622 time 6.164265394210815\n"
     ]
    }
   ],
   "source": [
    "# for weight in [None,'balanced']:\n",
    "for shrinkage in ['auto', None]:    \n",
    "    for solver in ['svd', 'lsqr', 'eigen']:\n",
    "        if shrinkage == 'auto':\n",
    "            temp_shrinkage = 'auto'\n",
    "        else:\n",
    "            temp_shrinkage = 'None'\n",
    "        try:\n",
    "            print(temp_shrinkage, solver)\n",
    "            clf = LinearDiscriminantAnalysis(shrinkage=shrinkage, solver=solver)\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred = clf.predict(X_test)\n",
    "            times.append(time.time())\n",
    "            test_acc = accuracy_score(y_test, pred)\n",
    "            test_f1 = f1_score(y_test, pred, average='weighted') \n",
    "            print('acc {} f1 {} time {}'.format(round(test_acc,3),round(test_f1,3), times[-1]-times[-2]))\n",
    "            clf = None\n",
    "            del clf\n",
    "            pred = None\n",
    "            del pred\n",
    "        except:\n",
    "            print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91bb928",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62f7d1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 gbtree\n",
      "acc 0.675 f1 0.675 time 22.27203869819641\n",
      "0.1 gblinear\n",
      "acc 0.633 f1 0.627 time 22.450019598007202\n",
      "0.1 dart\n",
      "acc 0.675 f1 0.675 time 31.458714723587036\n",
      "0.3 gbtree\n",
      "acc 0.685 f1 0.685 time 22.093270301818848\n",
      "0.3 gblinear\n",
      "acc 0.635 f1 0.629 time 22.373468160629272\n",
      "0.3 dart\n",
      "acc 0.685 f1 0.685 time 31.531245231628418\n",
      "0.5 gbtree\n",
      "acc 0.683 f1 0.683 time 21.534498929977417\n",
      "0.5 gblinear\n",
      "acc 0.635 f1 0.628 time 22.452567100524902\n",
      "0.5 dart\n",
      "acc 0.683 f1 0.683 time 31.19697070121765\n"
     ]
    }
   ],
   "source": [
    "booster = ['gbtree', 'gblinear', 'dart']\n",
    "eta = [0.1, 0.3, 0.5]\n",
    "# for weight in [None,'balanced']:\n",
    "for eta in [0.1, 0.3, 0.5]:    \n",
    "#     for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    for booster in ['gbtree', 'gblinear', 'dart']:\n",
    "        print(eta, booster)\n",
    "        clf = XGBClassifier(device='cuda', eta=eta, booster=booster)\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        times.append(time.time())\n",
    "        test_acc = accuracy_score(y_test, pred)\n",
    "        test_f1 = f1_score(y_test, pred, average='weighted') \n",
    "        print('acc {} f1 {} time {}'.format(round(test_acc,3),round(test_f1,3), times[-1]-times[-2]))\n",
    "        clf = None\n",
    "        del clf\n",
    "        pred = None\n",
    "        del pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10da252",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11354ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClass 0.05\n",
      "acc 0.741 f1 0.73 time 21.89696455001831\n"
     ]
    }
   ],
   "source": [
    "booster = ['gbtree', 'gblinear', 'dart']\n",
    "eta = [0.1, 0.3, 0.5]\n",
    "loss_function = ['RMSE','Logloss','MAE','CrossEntropy', 'Quantile','LogLinQuantile', 'Lq','MultiRMSE','MultiClass',\n",
    "                 'MultiClassOneVsAll','MultiLogloss','MultiCrossEntropy','MAPE','Poisson',\n",
    "                 'PairLogit','PairLogitPairwise','QueryRMSE','QuerySoftMax', 'Tweedie','YetiRank',\n",
    "                 'YetiRankPairwise','StochasticFilter','StochasticRank']\n",
    "learning_rate = [0.01, 0.03, 0.05]\n",
    "\n",
    "times.append(time.time())\n",
    "for loss in ['MultiClass']:    \n",
    "    for learning_rate in [0.05]:\n",
    "        print(loss, learning_rate)\n",
    "        clf = CatBoostClassifier(task_type=\"GPU\",\n",
    "                                devices='0:0', \n",
    "                                loss_function=loss, \n",
    "                                learning_rate=learning_rate,\n",
    "                                verbose=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        times.append(time.time())\n",
    "        test_acc = accuracy_score(y_test, pred)\n",
    "        test_f1 = f1_score(y_test, pred, average='weighted') \n",
    "        print('acc {} f1 {} time {}'.format(round(test_acc,3),round(test_f1,3), times[-1]-times[-2]))\n",
    "        clf = None\n",
    "        del clf\n",
    "        pred = None\n",
    "        del pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81858826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_lr.joblib']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "from joblib import load\n",
    "dump(clf_svm, 'clf_svm.joblib')\n",
    "dump(clf_cat, 'clf_cat.joblib')\n",
    "dump(clf_knn, 'clf_knn.joblib')\n",
    "dump(clf_lr, 'clf_lr.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67a5a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('./Модели ML/clf_lr.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9d85fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f38de11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
