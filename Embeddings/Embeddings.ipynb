{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd8aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef1e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# from datasets import Dataset, DatasetDict\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import sys\n",
    "import gc\n",
    "# import os\n",
    "# import time\n",
    "# from pprint import pprint\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.utils import shuffle\n",
    "import nltk\n",
    "# import nltk.corpus\n",
    "# import nltk.tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "import gensim.downloader\n",
    "# import string\n",
    "import gensim\n",
    "# from string import punctuation\n",
    "# import torch\n",
    "# import torch.autograd as autograd\n",
    "# from torchtext import vocab\n",
    "# import torch.nn as nn\n",
    "# from torch.autograd import Variable\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import  DataLoader\n",
    "# from sklearn.metrics import classification_report\n",
    "# import torch.utils.data as data_utils\n",
    "# from sklearn.metrics import classification_report\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import f1_score\n",
    "# from collections import Counter\n",
    "# from torch.utils.data.sampler import WeightedRandomSampler\n",
    "# from torchsampler import ImbalancedDatasetSampler\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a25a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(word):\n",
    "    if word in word2idx.keys():\n",
    "        return word2idx[word]\n",
    "    return word2idx[\"unk\"]\n",
    "word2idx = {word: idx for idx, word in enumerate(word2vec.index_to_key )}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b13c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_emb(emb_vectors, sent, emb_type, min_length, max_length):\n",
    "    ans = []\n",
    "    flag = True\n",
    "    word_count = 0\n",
    "    if emb_type == 'mean':\n",
    "        if type(sent)==str:\n",
    "            sent = sent.split()\n",
    "            for word in sent:\n",
    "                try:\n",
    "                    if flag:\n",
    "                        ans = emb_vectors[word]\n",
    "                        word_count += 1\n",
    "                        flag = False\n",
    "                    else:\n",
    "                        ans = list(map(sum, zip(ans, emb_vectors[word])))\n",
    "                        word_count += 1\n",
    "                except:\n",
    "                    continue\n",
    "        elif type(sent)==list:\n",
    "            sent = sent\n",
    "            for word in sent:\n",
    "                try:\n",
    "                    if flag:\n",
    "                        ans = emb_vectors[word]\n",
    "                        word_count += 1\n",
    "                        flag = False\n",
    "                    else:\n",
    "                        ans = list(map(sum, zip(ans, emb_vectors[word])))\n",
    "                        word_count += 1\n",
    "                except:\n",
    "                    continue   \n",
    "        if word_count > min_length and word_count < max_length:\n",
    "            ans = list(np.array(ans) / word_count)\n",
    "            sent = None; del sent; \n",
    "            return ans\n",
    "        else:\n",
    "            ans = list(np.array(ans) / word_count)\n",
    "            ans, sent = None, None; del ans, sent; \n",
    "            return []        \n",
    "    elif emb_type == 'sequence':\n",
    "        if type(sent)==str:\n",
    "            sent = sent.split()\n",
    "            for word in sent:\n",
    "                try:\n",
    "                    if flag:\n",
    "                        ans = emb_vectors[word]\n",
    "                        word_count += 1\n",
    "                        flag = False\n",
    "                    else:\n",
    "                        ans = ans.append(emb_vectors[word])\n",
    "                        word_count += 1\n",
    "                except:\n",
    "                    continue\n",
    "        elif type(sent)==list:\n",
    "            sent = sent\n",
    "            for word in sent:\n",
    "                try:\n",
    "                    if flag:\n",
    "                        ans = [emb_vectors[word]]\n",
    "                        word_count += 1\n",
    "                        flag = False\n",
    "                    else:\n",
    "                        ans.append(emb_vectors[word])\n",
    "                        word_count += 1\n",
    "                except:\n",
    "                    continue   \n",
    "        if word_count > min_length and word_count < max_length:\n",
    "            sent = None; del sent; \n",
    "            return ans\n",
    "        else:\n",
    "            ans, sent = None, None; del ans, sent; \n",
    "            return []   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c585eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_name = 'glove.6B.300d.txt'\n",
    "try:\n",
    "    word2vec = gensim.downloader.load(emb_name)\n",
    "except:\n",
    "    try:\n",
    "        word2vec = KeyedVectors.load_word2vec_format('../Эмбеддинги/'+emb_name, binary=False)\n",
    "    except:\n",
    "        word2vec = KeyedVectors.load_word2vec_format('../Эмбеддинги/'+emb_name, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(sentences=text_, vector_size=300, window=5, min_count=1, workers=4)\n",
    "w2v_model.build_vocab(df['lemma'])\n",
    "w2v_model.train(df['lemma'], total_examples=w2v_model.corpus_count, epochs=1, report_delay=1)\n",
    "w2v_model.init_sims(replace=True)\n",
    "w2v_model.save('emb_model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39d8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5c353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd63942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2c5b89e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a9b66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402cc5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f5a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802d22f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
